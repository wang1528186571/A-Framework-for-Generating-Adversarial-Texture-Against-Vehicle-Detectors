# A Framework for Generating Adversarial Texture Against Vehicle Detectors

## Abstract

Adversarial attacks on autonomous driving perception have recently attracted increasing research interest. Despite many physical-world approaches, their effectiveness often deteriorates in real road settings, with limited transfer across changes in viewpoint, distance, and illumination. To address this, we introduce a unified training framework spanning the multi-scale vehicle surface domain, simultaneously optimizing different scales vehicle adversarial textures to improve attack efficacy in both digital and physical environments. The framework incorporates an illumination-consistency module that corrects lighting discrepancies between the textured vehicle and its background, preserving photometric coherence across viewpoints and imaging conditions. Extensive experiments in both digital and physical environments show that, compared with existing methods, our method achieves higher and more stable attack success rates across mainstream detectors and exhibits stronger cross-model and cross-scene generalization.

## Demonstration

:hourglass: **Visualization video is being uploaded! Please check back later.**
